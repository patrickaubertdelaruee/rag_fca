{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f90c12-1184-46bb-96fd-2ad1f1c4672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import ollama\n",
    "import pypdf\n",
    "import weaviate\n",
    "from weaviate.connect import ConnectionParams\n",
    "from weaviate.classes.init import AdditionalConfig, Timeout, Auth\n",
    "import weaviate.classes.config as wc\n",
    "import weaviate.classes.query as wq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000ee9a0-ce90-4ed7-93a6-e61ee68800fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa4ce85-0632-4050-8d86-10d4f29f1a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_weaviate = weaviate.WeaviateClient(\n",
    "    connection_params=ConnectionParams.from_params(\n",
    "        http_host=\"weaviate\",\n",
    "        http_port=\"8081\",\n",
    "        http_secure=False,\n",
    "        grpc_host=\"weaviate\",\n",
    "        grpc_port=\"50051\",\n",
    "        grpc_secure=False,\n",
    "    ),\n",
    "    additional_config=AdditionalConfig(\n",
    "        timeout=Timeout(init=30, query=60, insert=120),  # Values in seconds\n",
    "    ),\n",
    "    skip_init_checks=False\n",
    ")\n",
    "\n",
    "client_weaviate.connect()  # When directly instantiating, you need to connect manually\n",
    "\n",
    "client_weaviate.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05904d7-46cf-4443-be57-2286ad86ca4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x7fe522a58610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_weaviate.collections.delete(\"FCA\")\n",
    "client_weaviate.collections.create(\n",
    "    name=\"FCA\",\n",
    "    properties=[\n",
    "        wc.Property(name=\"idx\", data_type=wc.DataType.INT, skip_vectorization=True),\n",
    "        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n",
    "    ],\n",
    "    # Define the vectorizer module\n",
    "    vectorizer_config=[\n",
    "        wc.Configure.NamedVectors.text2vec_ollama(\n",
    "            name=\"ollama_vectorizer\",\n",
    "            api_endpoint=\"http://ollama:11434\",\n",
    "            model=\"nomic-embed-text\",\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da00b8f-f70a-4fc5-b0db-d427a51b4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file_name: Path) -> str:\n",
    "    pdf_file = pypdf.PdfReader(pdf_file_name)\n",
    "    return \" \".join((page.extract_text() for page in pdf_file.pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79932cc8-feca-4431-8516-a7c977b870b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(input_text: str, chunk_size: int, chunk_overlap: int) -> list:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.create_documents([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5800230f-05a9-4ee5-a72b-6d016fc700a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/PDF\n",
      "Processing FCA1327-26_ADS_SysAdmin.pdf...\n",
      "FINISHED - create embeddings\n"
     ]
    }
   ],
   "source": [
    "root_dir = Path(os.getenv(\"PDF_DIR\"))\n",
    "print(root_dir)\n",
    "    \n",
    "chunk_size = int(os.getenv(\"CHUNK_SIZE\"))\n",
    "chunk_overlap = int(os.getenv(\"CHUNK_OVERLAP\"))\n",
    "\n",
    "collection = client_weaviate.collections.get(\"FCA\")\n",
    "\n",
    "for pdf_file_name in root_dir.glob(\"*.pdf\"):\n",
    "    print(f\"Processing {pdf_file_name.name}...\")\n",
    "    text = extract_text_from_pdf(pdf_file_name)\n",
    "    chunked_text = chunk_text(text, chunk_size, chunk_overlap)\n",
    "    for idx, chunk in enumerate(chunked_text):\n",
    "        content = chunk.page_content\n",
    "        collection.data.insert(\n",
    "            {\n",
    "                \"idx\": idx,\n",
    "                \"title\": pdf_file_name.name,\n",
    "                \"text\": content,\n",
    "            },\n",
    "        )\n",
    "print(\"FINISHED - create embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ca05bc-58a2-4715-a13b-3422c5f84e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 1971 embeddings\n"
     ]
    }
   ],
   "source": [
    "collection = client_weaviate.collections.get(\"FCA\")\n",
    "print(f\"Inserted {len(collection)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7323526-d4a8-42ee-aa9b-9813232489be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_near_vectors(collection_name: str, query_text: str, limit: int):\n",
    "    collection = client_weaviate.collections.get(collection_name)\n",
    "    return collection.query.near_text(\n",
    "        query=query_text,\n",
    "        limit=limit,\n",
    "        return_metadata=wq.MetadataQuery(distance=True),\n",
    "        return_properties=[\"idx\", \"text\", \"title\", ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbcb077-efb0-494b-9081-b059d66ae70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_vectors = get_near_vectors(\"FCA\", \"PermissionModelActive\", 4)\n",
    "context = [\n",
    "    {\"title\": str(vector.properties[\"title\"]), \"snippet\": vector.properties[\"text\"]}\n",
    "    for vector in near_vectors.objects\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92de20d-110f-4c7c-b12f-2264b79979c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The `PermissionModelActive` setting is not explicitly mentioned in the provided documents. However, I can explain its possible context based on the snippets you've provided.\n",
      "\n",
      "   In the Adobe Campaign Automation (ADS) system, permissions are managed to control user access to various resources. The command `entitlement_enable_all` is used to grant certain permissions for specified users across all servers. This suggests that settings like `PermissionModelActive` might be related to enabling or disabling permission models, allowing or denying specific actions on the ADM database.\n",
      "\n",
      "   I've used the following documents for my answer:\n",
      "   1. FCA1327-26_ADS_SysAdmin.pdf\n",
      "\n",
      "   While I could not find the exact setting `PermissionModelActive` in these documents, I hope this explanation helps you better understand its possible context. For more precise information, I recommend checking the official documentation or contacting Adobe support directly.\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain the setting PermissionModelActive. List the title of the documents.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "## Task & Context\n",
    "You help people answer their questions and other requests interactively. You will\n",
    "be asked a very wide array of requests on all kinds of topics. You will be\n",
    "equipped with a wide range of search engines or similar tools to help you,\n",
    "together with snippets from documents. You will use these to research your answer.\n",
    "You should focus on serving the user's needs as best you can.\n",
    "\n",
    "## Style Guide\n",
    "Unless the user asks for a different style of answer, you should answer in\n",
    "full sentences, using proper grammar and spelling.\n",
    "\n",
    "## Use these documents: {context}. Respond to this prompt: {query}. Cite the \n",
    "title of the documents you used for the answer.\n",
    "\"\"\"\n",
    "\n",
    "#client = Client(host='http://ollama:11434')\n",
    "\n",
    "output = ollama.generate(\n",
    "  model=\"mistral\",\n",
    "  prompt=prompt,\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a44b3-169e-4a0c-b3b7-e660f07a5a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87b6e5-501a-42b0-ac6b-28abed5cb0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
